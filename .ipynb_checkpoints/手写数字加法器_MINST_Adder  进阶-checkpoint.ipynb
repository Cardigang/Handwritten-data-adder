{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迁移学习——手写数字加法机\n",
    "实现了一个手写数字加法机，它可以通过识别输入的两个手写体图像文件，从而计算两个数字的和，并给出输出。展示了三种不同\n",
    "的迁移学习方式，并对它们进行了系统化的比较：\n",
    "\n",
    "1、没有迁移学习，网络完全从头学习如何识别数字，如何计算加法；\n",
    "\n",
    "2、将已训练好的手写数字识别器网络迁移过来，作为预训练权重；\n",
    "\n",
    "3、将已训练好的手写数字识别器网络迁移过来，并作为不可修改的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入所需要的包，请保证torchvision已经在你的环境中安装好\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、加载数据\n",
    "\n",
    "首先一个问题是如何加载成对的图像数据？我们采用的解决方案是采用了两套采样器和加载器，\n",
    "这样每一组采样器＋加载器都独立地从原始的数据集中抽样数据，这就让我们可以获得大量不重复\n",
    "的手写数字图像对，从而可以训练我们的神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 设置图像读取器的超参数\n",
    "image_size = 28  #图像的总尺寸28*28\n",
    "num_classes = 10  #标签的种类数\n",
    "num_epochs = 20  #训练的总循环周期\n",
    "batch_size = 64  #批处理的尺寸大小\n",
    "\n",
    "# 如果系统中存在着GPU，我们将用GPU来完成张量的计算\n",
    "use_cuda = torch.cuda.is_available() #定义一个布尔型变量，标志当前的GPU是否可用\n",
    "\n",
    "# 如果当前GPU可用，则将优先在GPU上进行张量计算\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "\n",
    "# 加载MINIST数据，如果没有下载过，就会在当前路径下新建/data子目录，并把文件存放其中\n",
    "# MNIST数据是属于torchvision包自带的数据，所以可以直接调用。\n",
    "# 在调用自己的数据的时候，我们可以用torchvision.datasets.ImageFolder或者torch.utils.data.TensorDataset来加载\n",
    "train_dataset = dsets.MNIST(root='./data',  #文件存放路径\n",
    "                            train=True,   #提取训练集\n",
    "                            transform=transforms.ToTensor(),  #将图像转化为Tensor\n",
    "                            download=True)\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# 定义两个采样器，每一个采样器都随机地从原始的数据集中抽样数据。抽样数据采用permutation\n",
    "# 生成任意一个下标重排，从而利用下标来提取dataset中的数据\n",
    "sample_size = len(train_dataset)\n",
    "sampler1 = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    np.random.choice(range(len(train_dataset)), sample_size))\n",
    "sampler2 = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    np.random.choice(range(len(train_dataset)), sample_size))\n",
    "\n",
    "# 定义两个加载器，分别封装了前两个采样器，实现采样。\n",
    "train_loader1 = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           sampler = sampler1\n",
    "                                           )\n",
    "train_loader2 = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           sampler = sampler2\n",
    "                                           )\n",
    "\n",
    "# 对于校验数据和测试数据，我们进行类似的处理。\n",
    "val_size = 5000\n",
    "val_indices1 = range(val_size)\n",
    "val_indices2 = np.random.permutation(range(val_size))\n",
    "test_indices1 = range(val_size, len(test_dataset))\n",
    "test_indices2 = np.random.permutation(test_indices1)\n",
    "val_sampler1 = torch.utils.data.sampler.SubsetRandomSampler(val_indices1)\n",
    "val_sampler2 = torch.utils.data.sampler.SubsetRandomSampler(val_indices2)\n",
    "\n",
    "test_sampler1 = torch.utils.data.sampler.SubsetRandomSampler(test_indices1)\n",
    "test_sampler2 = torch.utils.data.sampler.SubsetRandomSampler(test_indices2)\n",
    "\n",
    "val_loader1 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        sampler = val_sampler1\n",
    "                                        )\n",
    "val_loader2 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        sampler = val_sampler2\n",
    "                                        )\n",
    "test_loader1 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False,\n",
    "                                         sampler = test_sampler1\n",
    "                                         )\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False,\n",
    "                                         sampler = test_sampler2\n",
    "                                         )\n",
    "\n",
    "# 为了比较不同数据量对迁移学习的影响，我们设定了一个加载数据的比例fraction\n",
    "# 即我们只加载原训练数据集的1/fraction来训练网络\n",
    "fraction = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、加载网络\n",
    "\n",
    "为了实现迁移学习，我们需要从硬盘上加载已经训练好的手写数字识别器卷积神经网络，加载网络需要经过两个步骤：\n",
    "\n",
    "1、定义网络模块（nn.Module）的框架，即新定义类ConvNet，实现其forwar函数；\n",
    "\n",
    "2、从硬盘文件加载网络\n",
    "\n",
    "3、通过绘制其卷积核，验证加载到的网络和导出的网络一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义网络架构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义待迁移的网络框架，所有的神经网络模块包括：Conv2d、MaxPool2d，Linear等模块都不需要重新定义，会自动加载\n",
    "# 但是网络的forward功能没有办法自动实现，需要重写。\n",
    "# 一般的，加载网络只加载网络的属性，不加载方法\n",
    "depth = [4, 8]\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        # 将立体的Tensor全部转换成一维的Tensor。两次pooling操作，所以图像维度减少了1/4\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        x = F.relu(self.fc1(x)) #全链接，激活函数\n",
    "        x = F.dropout(x, training=self.training) #以默认为0.5的概率对这一层进行dropout操作\n",
    "        x = self.fc2(x) #全链接，激活函数\n",
    "        x = F.log_softmax(x, dim =1) #log_softmax可以理解为概率对数值\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 从硬盘文件加载网络\n",
    "\n",
    "网络加载命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_net = torch.load('minst_conv_checkpoint') #读取硬盘上的minst_conv_checkpoint文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc1): Linear(in_features=392, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_net #将网络打印出来观看（只能看到其神经模块和架构）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 检测加载的正确性\n",
    "\n",
    "通过测试它在测试数据集上的分类准确度，以及绘制其卷积核，并与导出的程序（minist_convnet.ipynb）中的分类准确度、卷积核等是否相同判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行10列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素\n",
    "\n",
    "#在测试集上分批运行，并计算总的正确率\n",
    "original_net.eval() #标志模型当前为运行阶段\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "vals = []\n",
    "\n",
    "#对测试数据集进行循环\n",
    "for data, target in test_loader1:\n",
    "#     data, target = data.clone().detach().requires_grad_(False), target.clone().detach()\n",
    "    with torch.no_grad():\n",
    "        data = data.clone().detach()\n",
    "    target = target.clone().detach()\n",
    "    \n",
    "    output = original_net(data) #将特征数据喂入网络，得到分类的输出\n",
    "    val = rightness(output, target) #获得正确样本数以及总样本数\n",
    "    vals.append(val) #记录结果\n",
    "\n",
    "#计算准确率\n",
    "rights = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n",
    "right_rate = 1.0 * rights[0].numpy() / rights[1]\n",
    "right_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签是： 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2fd37b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#随便从测试集中读入一张图片，并绘制出来\n",
    "idx = 4\n",
    "muteimg = test_dataset[idx][0].numpy()\n",
    "plt.imshow(muteimg[0,...])\n",
    "print('标签是：',test_dataset[idx][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAACcCAYAAABiB5/7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2fd3b1be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#提取第一层卷积层的卷积核\n",
    "plt.figure(figsize = (10, 7))\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i + 1)\n",
    "    plt.imshow(original_net.conv1.weight.data.numpy()[i,0,...])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAAIlCAYAAAC6mzu1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN8miGAB/mZWyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2b6432438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制第二层的卷积核\n",
    "plt.figure(figsize = (15, 10))\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        plt.subplot(4, 8, i * 8 + j + 1)\n",
    "        plt.imshow(original_net.conv2.weight.data.numpy()[j, i,...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、数字加法机的实现\n",
    "\n",
    "数字加法机：输入两张图像，输出这两个手写数字的加法。网络的架构如下：\n",
    "\n",
    "两个并行的卷积模块：两个卷积层、两个Pooling层；一个全链接模块：最多四层全链接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = [4, 8]\n",
    "class Transfer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transfer, self).__init__()\n",
    "        # 两个并行的卷积通道，第一个通道：\n",
    "        self.net1_conv1 = nn.Conv2d(1, 4, 5, padding = 2) #一个输入通道，4个输出通道（4个卷积核），窗口为5，填充2\n",
    "        self.net_pool = nn.MaxPool2d(2, 2) #2*2 池化\n",
    "        self.net1_conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2) #输入通道4，输出通道8（8个卷积核），窗口5，填充2\n",
    "        \n",
    "        # 第二个通道，注意pooling操作不需要重复定义\n",
    "        self.net2_conv1 = nn.Conv2d(1, 4, 5, padding = 2) #一个输入通道，4个输出通道（4个卷积核），窗口为5，填充2\n",
    "        self.net2_conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2) #输入通道4，输出通道8（8个卷积核），窗口5，填充2\n",
    "        \n",
    "        # 全链接层\n",
    "        self.fc1 = nn.Linear(2 * image_size // 4 * image_size // 4 * depth[1] , 1024) #输入为处理后的特征图压平，输出1024个单元\n",
    "        self.fc2 = nn.Linear(1024, 2 * num_classes) #输入1024个单元，输出20个单元\n",
    "        self.fc3 = nn.Linear(2 * num_classes, num_classes) #输入20个单元，输出10个单元\n",
    "        self.fc4 = nn.Linear(num_classes, 1) #输入10个单元，输出为1\n",
    "\n",
    "    def forward(self, x, y, training = True):\n",
    "        # 网络的前馈过程。输入两张手写图像x和y，输出一个数字表示两个数字的和\n",
    "        # x,y都是batch_size*image_size*image_size形状的三阶张量\n",
    "        # 输出为batch_size长的列向量\n",
    "        \n",
    "        # 首先，第一张图像进入第一个通道\n",
    "        x = F.relu(self.net1_conv1(x)) #第一层卷积\n",
    "        x = self.net_pool(x)   # 第一层池化\n",
    "        x = F.relu(self.net1_conv2(x))  # 第二层卷积\n",
    "        x = self.net_pool(x) # 第二层池化\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1]) # 将特征图张量压平\n",
    "        \n",
    "        \n",
    "        y = F.relu(self.net2_conv1(y)) #第一层卷积\n",
    "        y = self.net_pool(y) # 第一层池化\n",
    "        y = F.relu(self.net2_conv2(y)) #第二层卷积\n",
    "        y = self.net_pool(y) #第二层池化\n",
    "        y = y.view(-1, image_size // 4 * image_size // 4 * depth[1])# 将特征图张量压平\n",
    "        \n",
    "        # 将两个卷积过来的铺平向量拼接在一起，形成一个大向量\n",
    "        z = torch.cat((x, y), 1) #cat函数为拼接向量操作，1表示拼接的维度为第1个维度（0维度对应了batch）\n",
    "        z = self.fc1(z) #第一层全链接\n",
    "        z = F.relu(z)  #对于深层网络来说，激活函数用relu效果会比较好\n",
    "        z = F.dropout(z, training=self.training) #以默认为0.5的概率对这一层进行dropout操作\n",
    "        z = self.fc2(z) #第二层全链接\n",
    "        z = F.relu(z)\n",
    "        z = self.fc3(z) #第三层全链接\n",
    "        z = F.relu(z)\n",
    "        z = self.fc4(z) # 第四层全链接\n",
    "        return z\n",
    "    def set_filter_values(self, net):\n",
    "        # 本函数为迁移网络所用，即将迁移过来的网络的权重值拷贝到本网络中\n",
    "        # 本函数对应的迁移为预训练式\n",
    "        # 输入参数net为从硬盘加载的网络作为迁移源\n",
    "        \n",
    "        # 逐个儿为网络的两个卷积模块的权重和偏置进行赋值\n",
    "        # 注意在赋值的时候需要用deepcopy而不能直接等于，或者copy。\n",
    "        # 这是因为这种拷贝是将张量中的数值全部拷贝到了目标中，而不是拷贝地址\n",
    "        # 如果不用deepcopy，由于我们将同一组参数（net.conv1.weight.data,bias）\n",
    "        #  赋予了两组参数（net1_conv1.weight.data，net2_conv1.weight.data）\n",
    "        # 所以它们会共享源net.conv1.weight.data中的地址，这样对于net1_conv1.weight.data\n",
    "        # 的训练也自然会被用到了net2_conv1.weight.data中，但其实我们希望它们是两个不同的参数。\n",
    "        self.net1_conv1.weight.data = copy.deepcopy(net.conv1.weight.data)\n",
    "        self.net1_conv1.bias.data = copy.deepcopy(net.conv1.bias.data)\n",
    "        self.net1_conv2.weight.data = copy.deepcopy(net.conv2.weight.data)\n",
    "        self.net1_conv2.bias.data = copy.deepcopy(net.conv2.bias.data)\n",
    "        self.net2_conv1.weight.data = copy.deepcopy(net.conv1.weight.data)\n",
    "        self.net2_conv1.bias.data = copy.deepcopy(net.conv1.bias.data)\n",
    "        self.net2_conv2.weight.data = copy.deepcopy(net.conv2.weight.data)\n",
    "        self.net2_conv2.bias.data = copy.deepcopy(net.conv2.bias.data)\n",
    "        \n",
    "        # 将变量加载到GPU上        \n",
    "        self.net1_conv1 = self.net1_conv1.cuda() if use_cuda else self.net1_conv1\n",
    "        self.net1_conv2 = self.net1_conv2.cuda() if use_cuda else self.net1_conv2\n",
    "        \n",
    "        self.net2_conv1 = self.net2_conv1.cuda() if use_cuda else self.net2_conv1\n",
    "        self.net2_conv2 = self.net2_conv2.cuda() if use_cuda else self.net2_conv2\n",
    "    def set_filter_values_nograd(self, net):\n",
    "        # 本函数为迁移网络所用，即将迁移过来的网络的权重值拷贝到本网络中\n",
    "        # 本函数对应的迁移为固定权重式\n",
    "        # 调用set_filter_values为全部卷积核进行赋值\n",
    "        self.set_filter_values(net)\n",
    "        \n",
    "        # 为了让我们的网络不被训练调整权值，我们需要设定每一个变量的requires_grad为False\n",
    "        # 即不需要计算梯度值\n",
    "        self.net1_conv1.weight.requires_grad = False\n",
    "        self.net1_conv1.bias.requires_grad = False\n",
    "        self.net1_conv2.weight.requires_grad = False\n",
    "        self.net1_conv2.bias.requires_grad = False\n",
    "        \n",
    "        \n",
    "        self.net2_conv1.weight.requires_grad = False\n",
    "        self.net2_conv1.bias.requires_grad = False\n",
    "        self.net2_conv2.weight.requires_grad = False\n",
    "        self.net2_conv2.bias.requires_grad = False\n",
    "def rightness(y, target):\n",
    "    # 计算分类准确度的函数，y为模型预测的标签，target为数据的标签\n",
    "    # 输入的y为一个矩阵，行对应了batch中的不同数据记录，列对应了不同的分类选择，数值对应了概率\n",
    "    # 函数输出分别为预测与数据标签相等的个数，本次判断的所有数据个数\n",
    "    out = torch.round(y.squeeze()).type(itype)\n",
    "    out = out.eq(target).sum()\n",
    "    out1 = y.size()[0]\n",
    "    return(out, out1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、数据迁移实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 无迁移实验\n",
    "\n",
    "在本试验中，我们不迁移网络，直接训练整个网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成网络实例\n",
    "net = Transfer()\n",
    "\n",
    "# 如果存在GPU，则将网络加载到GPU中\n",
    "if use_cuda:\n",
    "    net = net.cuda()\n",
    "    \n",
    "# 定义损失函数，我们用最小均方误差来定义损失\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0周期，第(0/938)个撮，训练误差：88.88827514648438, 校验误差：99.46, 准确率：0.01\n",
      "第0周期，第(100/938)个撮，训练误差：81.66851043701172, 校验误差：51.54, 准确率：0.05\n",
      "第0周期，第(200/938)个撮，训练误差：51.268524169921875, 校验误差：17.43, 准确率：0.10\n",
      "第0周期，第(300/938)个撮，训练误差：39.87971115112305, 校验误差：16.58, 准确率：0.10\n",
      "第0周期，第(400/938)个撮，训练误差：34.11788558959961, 校验误差：16.68, 准确率：0.11\n",
      "第0周期，第(500/938)个撮，训练误差：30.676992416381836, 校验误差：17.10, 准确率：0.11\n",
      "第0周期，第(600/938)个撮，训练误差：28.45798683166504, 校验误差：16.70, 准确率：0.10\n",
      "第0周期，第(700/938)个撮，训练误差：26.859600067138672, 校验误差：17.01, 准确率：0.09\n",
      "第0周期，第(800/938)个撮，训练误差：25.62700653076172, 校验误差：16.87, 准确率：0.11\n",
      "第0周期，第(900/938)个撮，训练误差：24.621925354003906, 校验误差：16.49, 准确率：0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1周期，第(0/938)个撮，训练误差：14.214404106140137, 校验误差：16.97, 准确率：0.09\n",
      "第1周期，第(100/938)个撮，训练误差：16.6541805267334, 校验误差：17.21, 准确率：0.11\n",
      "第1周期，第(200/938)个撮，训练误差：16.7957763671875, 校验误差：16.96, 准确率：0.11\n",
      "第1周期，第(300/938)个撮，训练误差：16.799388885498047, 校验误差：16.82, 准确率：0.09\n",
      "第1周期，第(400/938)个撮，训练误差：16.87097930908203, 校验误差：16.96, 准确率：0.09\n",
      "第1周期，第(500/938)个撮，训练误差：16.895231246948242, 校验误差：17.11, 准确率：0.10\n",
      "第1周期，第(600/938)个撮，训练误差：16.902414321899414, 校验误差：16.37, 准确率：0.10\n",
      "第1周期，第(700/938)个撮，训练误差：16.876432418823242, 校验误差：16.96, 准确率：0.10\n",
      "第1周期，第(800/938)个撮，训练误差：16.895774841308594, 校验误差：16.77, 准确率：0.10\n",
      "第1周期，第(900/938)个撮，训练误差：16.85071563720703, 校验误差：16.49, 准确率：0.10\n",
      "第2周期，第(0/938)个撮，训练误差：16.263442993164062, 校验误差：17.16, 准确率：0.10\n",
      "第2周期，第(100/938)个撮，训练误差：16.845544815063477, 校验误差：16.51, 准确率：0.11\n",
      "第2周期，第(200/938)个撮，训练误差：16.631534576416016, 校验误差：16.80, 准确率：0.10\n",
      "第2周期，第(300/938)个撮，训练误差：16.66823387145996, 校验误差：16.30, 准确率：0.10\n",
      "第2周期，第(400/938)个撮，训练误差：16.696725845336914, 校验误差：16.62, 准确率：0.10\n",
      "第2周期，第(500/938)个撮，训练误差：16.706571578979492, 校验误差：16.46, 准确率：0.10\n",
      "第2周期，第(600/938)个撮，训练误差：16.736026763916016, 校验误差：17.22, 准确率：0.10\n",
      "第2周期，第(700/938)个撮，训练误差：16.74675750732422, 校验误差：16.99, 准确率：0.10\n",
      "第2周期，第(800/938)个撮，训练误差：16.786096572875977, 校验误差：16.73, 准确率：0.09\n",
      "第2周期，第(900/938)个撮，训练误差：16.82909393310547, 校验误差：16.51, 准确率：0.10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 开始训练网络\n",
    "num_epochs = 20\n",
    "records = []\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    \n",
    "    # 我们可以用zip命令来同时从两个数据加载器中加载数据，enumerate则给这个迭代附加上了计数\n",
    "    for idx, data in enumerate(zip(train_loader1, train_loader2)):\n",
    "        # 为了比较数据量大小对迁移学习的影响，我们只加载了部分数据，当数据加载个数idx大于\n",
    "        # 全数据集的1/fraction的时候则不再加载后面的数据\n",
    "        if idx >= (len(train_loader1) // fraction):\n",
    "            break\n",
    "        ((x1, y1), (x2, y2)) = data\n",
    "        if use_cuda:\n",
    "            x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        net.train()\n",
    "        outputs = net(x1.clone().detach(), x2.clone().detach())\n",
    "        labels = y1 + y2\n",
    "        loss = criterion(outputs, labels.type(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        losses.append(loss.data.numpy())\n",
    "        if idx % 100 == 0:\n",
    "            # 在校验数据上计算计算准确率\n",
    "            val_losses = []\n",
    "            rights = []\n",
    "            net.eval()\n",
    "            for val_data in zip(val_loader1, val_loader2):\n",
    "                ((x1, y1), (x2, y2)) = val_data\n",
    "                if use_cuda:\n",
    "                    x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "                outputs = net(x1.clone().detach(), x2.clone().detach())\n",
    "                labels = y1 + y2\n",
    "                \n",
    "                loss = criterion(outputs, labels.type(torch.float))\n",
    "                loss = loss.cpu() if use_cuda else loss\n",
    "                val_losses.append(loss.data.numpy())\n",
    "                \n",
    "                right = rightness(outputs.data, labels)\n",
    "                rights.append(right)\n",
    "            right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "            print('第{}周期，第({}/{})个撮，训练误差：{}, 校验误差：{:.2f}, 准确率：{:.2f}'.format(\n",
    "                epoch, idx, len(train_loader1),\n",
    "                np.mean(losses), np.mean(val_losses), right_ratio))\n",
    "            records.append([np.mean(losses), np.mean(val_losses), right_ratio])\n",
    "\n",
    "# 在测试数据集上测试准确度\n",
    "rights = []\n",
    "net.eval()\n",
    "for test_data in zip(test_loader1, test_loader2):\n",
    "    ((x1, y1), (x2, y2)) = test_data\n",
    "    if use_cuda:\n",
    "        x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "    outputs = net(x1.clone().detach(), x2.clone().detach())\n",
    "    labels = y1 + y2\n",
    "    loss = criterion(outputs, labels.type(torch.float))\n",
    "    right = rightness(outputs.data, labels)\n",
    "    rights.append(right)\n",
    "right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "results['notransfer'] = [records, right_ratio]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 绘制实验结果，打印测试集上的准确度\n",
    "plt.plot([i[0] for i in records])\n",
    "plt.plot([i[1] for i in records])\n",
    "plt.plot([100 * (1 - i[2]) for i in records])\n",
    "right_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 迁移网络，预训练\n",
    "\n",
    "在本试验中，我们将手写数字识别的卷积神经网络权重迁移过来，作为新的加法机网络的预训练值（也就是初始值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Transfer()\n",
    "\n",
    "# 为新网络赋予权重数值，注意我们只将卷积部分的网络进行迁移，而没有迁移全链接层\n",
    "net.set_filter_values(original_net)\n",
    "\n",
    "if use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 将需要训练的参数加载到优化器中\n",
    "new_parameters = []\n",
    "for para in net.parameters():\n",
    "    if para.requires_grad: #我们只将可以调整权重的变量加到了集合new_parameters\n",
    "        new_parameters.append(para)\n",
    "        \n",
    "# 将new_parameters加载到了优化器中\n",
    "optimizer = optim.SGD(new_parameters, lr=0.0001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 开始训练网络\n",
    "num_epochs = 20\n",
    "records = []\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for idx, data in enumerate(zip(train_loader1, train_loader2)):\n",
    "        if idx >= (len(train_loader1) // fraction):\n",
    "            break\n",
    "        ((x1, y1), (x2, y2)) = data\n",
    "        if use_cuda:\n",
    "            x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "        labels = y1 + y2\n",
    "        loss = criterion(outputs,labels.type(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        losses.append(loss.data.numpy())\n",
    "        if idx % 100 == 0:\n",
    "            val_losses = []\n",
    "            rights = []\n",
    "            net.eval()\n",
    "            for val_data in zip(val_loader1, val_loader2):\n",
    "                ((x1, y1), (x2, y2)) = val_data\n",
    "                if use_cuda:\n",
    "                    x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "                outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "                labels = y1 + y2\n",
    "                loss = criterion(outputs, labels.type(torch.float))\n",
    "                loss = loss.cpu() if use_cuda else loss\n",
    "                val_losses.append(loss.data.numpy())\n",
    "                \n",
    "                right = rightness(outputs.data, labels)\n",
    "                rights.append(right)\n",
    "            right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "            print('第{}周期，第({}/{})个撮，训练误差：{:.2f}, 校验误差：{:.2f}, 准确率：{:.2f}'.format(\n",
    "                epoch, idx, len(train_loader1),\n",
    "                np.mean(losses), np.mean(val_losses), right_ratio))\n",
    "            records.append([np.mean(losses), np.mean(val_losses), right_ratio])\n",
    "rights = []\n",
    "net.eval()\n",
    "for test_data in zip(test_loader1, test_loader2):\n",
    "    ((x1, y1), (x2, y2)) = test_data\n",
    "    if use_cuda:\n",
    "        x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "    outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "    labels = y1 + y2\n",
    "    loss = criterion(outputs, labels.type(torch.float))\n",
    "    right = rightness(outputs.data, labels)\n",
    "    rights.append(right)\n",
    "right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "results['transfer_pretrained'] = [records, right_ratio] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot([1 - i[2] for i in records])\n",
    "right_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.迁移，不更新权重\n",
    "\n",
    "在这个试验中，我们首先将识别器的卷积层的权重全部迁移到了加法机的两个卷积部件中，但保持它们的权重不变，只允许后面的全链接层的权重可训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Transfer()\n",
    "# 迁移网络，并设置卷积部件的权重和偏置都不计算梯度\n",
    "net.set_filter_values_nograd(original_net)\n",
    "if use_cuda:\n",
    "    net = net.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 只将可更新的权重值加载到了优化器中\n",
    "new_parameters = []\n",
    "for para in net.parameters():\n",
    "    if para.requires_grad:\n",
    "        new_parameters.append(para)\n",
    "optimizer = optim.SGD(new_parameters, lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 训练整个网络\n",
    "num_epochs = 20\n",
    "records = []\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for idx, data in enumerate(zip(train_loader1, train_loader2)):\n",
    "        if idx >= (len(train_loader1) // fraction):\n",
    "            break\n",
    "        ((x1, y1), (x2, y2)) = data\n",
    "        if use_cuda:\n",
    "            x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "        labels = y1 + y2\n",
    "        labels = labels.type(dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        losses.append(loss.data.numpy())\n",
    "        if idx % 100 == 0:\n",
    "            val_losses = []\n",
    "            rights = []\n",
    "            net.eval()\n",
    "            for val_data in zip(val_loader1, val_loader2):\n",
    "                ((x1, y1), (x2, y2)) = val_data\n",
    "                if use_cuda:\n",
    "                    x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "                outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "                labels = y1 + y2\n",
    "                loss = criterion(outputs, labels.type(torch.float))\n",
    "                loss = loss.cpu() if use_cuda else loss\n",
    "                val_losses.append(loss.data.numpy())\n",
    "                \n",
    "                right = rightness(outputs.data, labels)\n",
    "                rights.append(right)\n",
    "            right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "            print('第{}周期，第({}/{})个撮，训练误差：{:.2f}, 校验误差：{:.2f}, 准确率：{:.2f}'.format(\n",
    "                epoch, idx, len(train_loader1),\n",
    "                np.mean(losses), np.mean(val_losses), right_ratio))\n",
    "            records.append([np.mean(losses), np.mean(val_losses), right_ratio])\n",
    "rights = []\n",
    "net.eval()\n",
    "for test_data in zip(test_loader1, test_loader2):\n",
    "    ((x1, y1), (x2, y2)) = test_data\n",
    "    if use_cuda:\n",
    "        x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "    outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "    labels = y1 + y2\n",
    "    loss = criterion(outputs, labels.type(torch.float))\n",
    "    right = rightness(outputs.data, labels)\n",
    "    rights.append(right)\n",
    "right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "results['transfer_fixed'] = [records, right_ratio]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot([1 - i[2] for i in records])\n",
    "right_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、结果比较\n",
    "将三次实验的结果放到一起比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1, y2, y3 = results['notransfer'][0], results['transfer_pretrained'][0], results['transfer_fixed'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot([1 - i[2] for i in y1], 'o-', label = 'no transfer')\n",
    "plt.plot([1 - i[2] for i in y2], 's:', label = 'transfer pretrained')\n",
    "plt.plot([1 - i[2] for i in y3], '*-', label = 'transfer fixed')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['notransfer'][1], results['transfer_pretrained'][1], results['transfer_fixed'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "experiments[1] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 综合试验\n",
    "\n",
    "为了系统化的比较不同的参数对迁移学习的影响，我们做了一次大实验：\n",
    "\n",
    "该试验包括了三重循环，分别是：\n",
    "\n",
    "1、不同的迁移学习方法：无迁移、迁移固定权重、迁移预训练\n",
    "\n",
    "2、每一个参数下重复实验times次\n",
    "\n",
    "3、加载不同的数据集比例fraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {} #记载实验结果\n",
    "times = 10 # 每一组参数下实验都要被重复10次\n",
    "fractions = [20, 10, 8, 6, 5, 4, 3, 2, 1] #所有的数据加载的比例值\n",
    "for experiment in ['no transfer', 'transfer_fixed', 'transfer_pretrained']:\n",
    "    for time in range(times):\n",
    "        for fraction in fractions:\n",
    "            \n",
    "            # 分不同的迁移学习情况加载网络和优化器\n",
    "            if experiment == 'no transfer':\n",
    "                net = Transfer()\n",
    "                if use_cuda:\n",
    "                    net = net.cuda()\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)\n",
    "            if experiment == 'transfer_pretrained':\n",
    "                net = Transfer()\n",
    "                net.set_filter_values(original_net)\n",
    "                if use_cuda:\n",
    "                    net = net.cuda()\n",
    "                criterion = nn.MSELoss()\n",
    "                new_parameters = []\n",
    "                for para in net.parameters():\n",
    "                    if para.requires_grad:\n",
    "                        new_parameters.append(para)\n",
    "                optimizer = optim.SGD(new_parameters, lr=0.0001, momentum=0.9)\n",
    "            if experiment == 'transfer_fixed':\n",
    "                net = Transfer()\n",
    "                net.set_filter_values_nograd(original_net)\n",
    "                if use_cuda:\n",
    "                    net = net.cuda()\n",
    "                criterion = nn.MSELoss()\n",
    "                new_parameters = []\n",
    "                for para in net.parameters():\n",
    "                    if para.requires_grad:\n",
    "                        new_parameters.append(para)\n",
    "                optimizer = optim.SGD(new_parameters, lr=0.0001, momentum=0.9)\n",
    "                \n",
    "            #开始迁移学习训练\n",
    "            num_epochs = 20\n",
    "            records = []\n",
    "            for epoch in range(num_epochs):\n",
    "                losses = []\n",
    "                for idx, data in enumerate(zip(train_loader1, train_loader2)):\n",
    "                    if idx >= (len(train_loader1) // fraction):\n",
    "                        break\n",
    "                    ((x1, y1), (x2, y2)) = data\n",
    "                    if use_cuda:\n",
    "                        x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "                    net.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "                    labels = y1 + y2\n",
    "                    loss = criterion(outputs, labels.type(dtype))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    loss = loss.cpu() if use_cuda else loss\n",
    "                    losses.append(loss.data.numpy())\n",
    "                    if idx % 500 == 0:\n",
    "                        val_losses = []\n",
    "                        rights = []\n",
    "                        net.eval()\n",
    "                        for val_data in zip(val_loader1, val_loader2):\n",
    "                            ((x1, y1), (x2, y2)) = val_data\n",
    "                            if use_cuda:\n",
    "                                x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "                            outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "                            labels = y1 + y2\n",
    "                            loss = criterion(outputs, labels.type(dtype))\n",
    "                            loss = loss.cpu() if use_cuda else loss\n",
    "                            val_losses.append(loss.data.numpy())\n",
    "                            right = rightness(outputs.data, labels)\n",
    "                            rights.append(right)\n",
    "                        right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "                        print('{}网络：第{}试验，比例{}, 第{}周期，第({}/{})个撮，训练误差：{:.2f}, 校验误差：{:.2f}, 准确率：{:.2f}'\n",
    "                              .format(experiment,time,fraction,\n",
    "                            epoch, idx, len(train_loader1),\n",
    "                            np.mean(losses), np.mean(val_losses), right_ratio))\n",
    "                        records.append([np.mean(losses), np.mean(val_losses), right_ratio])\n",
    "            rights = []\n",
    "            net.eval()\n",
    "            for test_data in zip(test_loader1, test_loader2):\n",
    "                ((x1, y1), (x2, y2)) = test_data\n",
    "                if use_cuda:\n",
    "                    x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "                outputs = net(x1.clone().detach().requires_grad_(True), x2.clone().detach().requires_grad_(True))\n",
    "                labels = y1 + y2\n",
    "                loss = criterion(outputs, labels.type(dtype))\n",
    "                right = rightness(outputs.data, labels)\n",
    "                rights.append(right)\n",
    "            right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "            print(experiment,time,fraction)\n",
    "            \n",
    "            #将结果记录在了results集合之中，records记载了每一个打印周期的训练集损失函数、校验集损失函数、校验集正确率，\n",
    "            #right_ratio记录了每次实验测试集的准确度\n",
    "            results[(experiment,time,fraction)] = [records, right_ratio]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 处理实验数据\n",
    "# 首先对于同一组参数下的数据求多次试验的平均值\n",
    "\n",
    "one_curve = {}\n",
    "tests = {}\n",
    "for experiment in ['no transfer', 'transfer_pretrained', 'transfer_fixed']:\n",
    "    for fraction in fractions:\n",
    "        one_experiment = []\n",
    "        test_value = []\n",
    "        for time in range(times):\n",
    "            rr = results[(experiment, time, fraction)]\n",
    "            one_experiment.append([ii[2] for ii in rr[0]])\n",
    "            test_value.append(rr[1])\n",
    "        aa = np.array(one_experiment)\n",
    "        #print(aa.shape)\n",
    "        one_curve[(experiment, fraction)] = np.mean(aa, 0)\n",
    "        tests[(experiment, fraction)] = np.mean(test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 然后再绘制它们的误差曲线\n",
    "for fraction in fractions:\n",
    "    plt.figure(figsize = (10, 7))\n",
    "    plt.title('{:.2f} % of the data'.format(100.0 / fraction))\n",
    "    plt.plot(1 - one_curve[('no transfer', fraction)], label = 'no transfer')\n",
    "    plt.plot(1 - one_curve[('transfer_pretrained', fraction)], label = 'transfer pretrained')\n",
    "    plt.plot(1 - one_curve[('transfer_fixed', fraction)] , label = 'transfer fixed')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 绘制测试准确度随着fraction变化的曲线\n",
    "plt.figure(figsize = (10, 7))\n",
    "for experiment in ['no transfer', 'transfer_pretrained', 'transfer_fixed']:\n",
    "    testss = []\n",
    "    for fraction in fractions:\n",
    "        test = 1 - tests[(experiment, fraction)]\n",
    "        testss.append(test)\n",
    "    plt.plot(fractions, testss, 'o-', label = experiment)\n",
    "plt.legend()\n",
    "plt.xlabel('Fractions')\n",
    "plt.ylabel('Error Rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
